{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftesting = pd.read_pickle(r'C:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\artifact\\testing_data1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'BERT4Rec' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the pre-trained model from the pickle file\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSOOQ ELASER\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmovie_recomendation_collaborative_filtering\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbert4rec_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m model_file:\n\u001b[1;32m----> 9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Specify the path to the test dataset\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSOOQ ELASER\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmovie_recomendation_collaborative_filtering\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124martifact\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesting_data1.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'BERT4Rec' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "\n",
    "# Load the pre-trained model from the pickle file\n",
    "with open(r'C:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\models\\bert4rec_model.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Specify the path to the test dataset\n",
    "test_data_path = r'C:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\artifact\\testing_data1.pkl' \n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_pickle(test_data_path)\n",
    "\n",
    "# Ensure data is sorted chronologically if needed\n",
    "test_df['datetime'] = pd.to_datetime(test_df['datetime'])\n",
    "test_df = test_df.sort_values(by=['userId', 'datetime'])\n",
    "\n",
    "# Function to create sequences of movies for each user (same as during training)\n",
    "def create_sequences(df, sequence_length=50):\n",
    "    user_sequences = []\n",
    "    user_ids = df['userId'].unique()\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        user_data = df[df['userId'] == user_id]\n",
    "        movie_sequence = user_data['movieId'].values\n",
    "        \n",
    "        for i in range(len(movie_sequence) - sequence_length):\n",
    "            user_sequences.append((movie_sequence[i:i + sequence_length], \n",
    "                                   list(range(sequence_length))))\n",
    "    \n",
    "    return user_sequences\n",
    "\n",
    "# Create sequences from the test data\n",
    "test_sequences = create_sequences(test_df)\n",
    "\n",
    "# Prepare the test data for model evaluation\n",
    "def prepare_data(sequences, sequence_length=50):\n",
    "    movie_sequences = [seq[0] for seq in sequences]\n",
    "    position_sequences = [seq[1] for seq in sequences]\n",
    "    next_movie = [seq[0][-1] for seq in sequences]\n",
    "    \n",
    "    movie_sequences_padded = pad_sequences(movie_sequences, padding='post', maxlen=sequence_length)\n",
    "    position_sequences_padded = pad_sequences(position_sequences, padding='post', maxlen=sequence_length)\n",
    "    \n",
    "    return np.array(movie_sequences_padded), np.array(position_sequences_padded), np.array(next_movie)\n",
    "\n",
    "# Prepare the test tensors\n",
    "test_movie_seq, test_position_seq, test_next_movie = prepare_data(test_sequences)\n",
    "test_movie_seq_tensor = tf.convert_to_tensor(test_movie_seq, dtype=tf.int32)\n",
    "test_position_seq_tensor = tf.convert_to_tensor(test_position_seq, dtype=tf.int32)\n",
    "test_next_movie_tensor = tf.convert_to_tensor(test_next_movie, dtype=tf.int32)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_metrics = model.evaluate(\n",
    "    [test_movie_seq_tensor, test_position_seq_tensor], \n",
    "    test_next_movie_tensor\n",
    ")\n",
    "\n",
    "print(\"Model Evaluation Results:\", evaluation_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>datetime</th>\n",
       "      <th>movie_sequence</th>\n",
       "      <th>genre_sequence</th>\n",
       "      <th>datetime_sequence</th>\n",
       "      <th>title_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131626</th>\n",
       "      <td>114818.0</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>11248.0</td>\n",
       "      <td>2015-01-06 13:57:40</td>\n",
       "      <td>[76755.0, 76755.0, 76755.0, 76755.0, 76755.0, ...</td>\n",
       "      <td>[65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 6...</td>\n",
       "      <td>[2011-07-12 19:10:21, 2011-07-12 19:10:21, 201...</td>\n",
       "      <td>[86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44208</th>\n",
       "      <td>32460.0</td>\n",
       "      <td>61</td>\n",
       "      <td>7</td>\n",
       "      <td>370.0</td>\n",
       "      <td>2008-06-19 20:16:53</td>\n",
       "      <td>[32460.0, 32460.0, 32460.0, 32460.0, 32460.0, ...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[2008-06-19 20:16:53, 2008-06-19 20:16:53, 200...</td>\n",
       "      <td>[61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99120</th>\n",
       "      <td>127319.0</td>\n",
       "      <td>120</td>\n",
       "      <td>65</td>\n",
       "      <td>3358.0</td>\n",
       "      <td>2015-03-29 06:28:21</td>\n",
       "      <td>[127323.0, 127323.0, 127323.0, 127323.0, 12732...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[2015-02-07 19:44:48, 2015-02-07 19:44:48, 201...</td>\n",
       "      <td>[126, 126, 126, 126, 126, 126, 126, 126, 126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90126</th>\n",
       "      <td>60365.0</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>2012-07-04 16:06:16</td>\n",
       "      <td>[6037.0, 6037.0, 6037.0, 6037.0, 6037.0, 6037....</td>\n",
       "      <td>[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...</td>\n",
       "      <td>[2003-01-19 07:00:33, 2003-01-19 07:00:33, 200...</td>\n",
       "      <td>[109, 109, 109, 109, 109, 109, 109, 109, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089</th>\n",
       "      <td>80846.0</td>\n",
       "      <td>24</td>\n",
       "      <td>62</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2011-03-06 23:14:10</td>\n",
       "      <td>[80094.0, 80094.0, 80094.0, 80094.0, 80094.0, ...</td>\n",
       "      <td>[63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 6...</td>\n",
       "      <td>[2011-01-08 16:42:21, 2011-01-08 16:42:21, 201...</td>\n",
       "      <td>[63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movieId  title  genres   userId            datetime  \\\n",
       "131626  114818.0    108       6  11248.0 2015-01-06 13:57:40   \n",
       "44208    32460.0     61       7    370.0 2008-06-19 20:16:53   \n",
       "99120   127319.0    120      65   3358.0 2015-03-29 06:28:21   \n",
       "90126    60365.0     39      27   1741.0 2012-07-04 16:06:16   \n",
       "10089    80846.0     24      62    129.0 2011-03-06 23:14:10   \n",
       "\n",
       "                                           movie_sequence  \\\n",
       "131626  [76755.0, 76755.0, 76755.0, 76755.0, 76755.0, ...   \n",
       "44208   [32460.0, 32460.0, 32460.0, 32460.0, 32460.0, ...   \n",
       "99120   [127323.0, 127323.0, 127323.0, 127323.0, 12732...   \n",
       "90126   [6037.0, 6037.0, 6037.0, 6037.0, 6037.0, 6037....   \n",
       "10089   [80094.0, 80094.0, 80094.0, 80094.0, 80094.0, ...   \n",
       "\n",
       "                                           genre_sequence  \\\n",
       "131626  [65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 6...   \n",
       "44208   [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "99120   [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "90126   [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 3...   \n",
       "10089   [63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 6...   \n",
       "\n",
       "                                        datetime_sequence  \\\n",
       "131626  [2011-07-12 19:10:21, 2011-07-12 19:10:21, 201...   \n",
       "44208   [2008-06-19 20:16:53, 2008-06-19 20:16:53, 200...   \n",
       "99120   [2015-02-07 19:44:48, 2015-02-07 19:44:48, 201...   \n",
       "90126   [2003-01-19 07:00:33, 2003-01-19 07:00:33, 200...   \n",
       "10089   [2011-01-08 16:42:21, 2011-01-08 16:42:21, 201...   \n",
       "\n",
       "                                           title_sequence  \n",
       "131626  [86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 8...  \n",
       "44208   [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...  \n",
       "99120   [126, 126, 126, 126, 126, 126, 126, 126, 126, ...  \n",
       "90126   [109, 109, 109, 109, 109, 109, 109, 109, 109, ...  \n",
       "10089   [63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 6...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftesting.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28773, 9)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftesting.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftraining = pd.read_pickle(r'C:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\artifact\\training_data1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>datetime</th>\n",
       "      <th>movie_sequence</th>\n",
       "      <th>genre_sequence</th>\n",
       "      <th>datetime_sequence</th>\n",
       "      <th>title_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109333</th>\n",
       "      <td>81140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>4450.0</td>\n",
       "      <td>2014-08-08 04:58:07</td>\n",
       "      <td>[6825.0, 6825.0, 6825.0, 6825.0, 6825.0, 6825....</td>\n",
       "      <td>[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3...</td>\n",
       "      <td>[2004-01-17 01:59:42, 2004-01-17 01:59:42, 200...</td>\n",
       "      <td>[94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65022</th>\n",
       "      <td>72224.0</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>739.0</td>\n",
       "      <td>2010-03-22 02:41:56</td>\n",
       "      <td>[72224.0, 72224.0, 72224.0, 72224.0, 72224.0, ...</td>\n",
       "      <td>[31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3...</td>\n",
       "      <td>[2010-03-22 02:41:56, 2010-03-22 02:41:56, 201...</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56562</th>\n",
       "      <td>91978.0</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>370.0</td>\n",
       "      <td>2013-03-30 14:58:41</td>\n",
       "      <td>[32460.0, 32460.0, 32460.0, 32460.0, 32460.0, ...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[2008-06-19 20:16:53, 2008-06-19 20:16:53, 200...</td>\n",
       "      <td>[61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119782</th>\n",
       "      <td>113501.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10164.0</td>\n",
       "      <td>2014-12-02 04:28:57</td>\n",
       "      <td>[113501.0, 113501.0, 113501.0, 113501.0, 11350...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[2014-12-02 04:28:57, 2014-12-02 04:28:57, 201...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24127</th>\n",
       "      <td>1502.0</td>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>359.0</td>\n",
       "      <td>2004-06-14 21:09:23</td>\n",
       "      <td>[3192.0, 3192.0, 3192.0, 3192.0, 3192.0, 3192....</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "      <td>[2003-10-26 16:08:07, 2003-10-26 16:08:07, 200...</td>\n",
       "      <td>[117, 117, 117, 117, 117, 117, 117, 117, 117, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movieId  title  genres   userId            datetime  \\\n",
       "109333   81140.0      1      62   4450.0 2014-08-08 04:58:07   \n",
       "65022    72224.0     43      31    739.0 2010-03-22 02:41:56   \n",
       "56562    91978.0     71      48    370.0 2013-03-30 14:58:41   \n",
       "119782  113501.0      3       5  10164.0 2014-12-02 04:28:57   \n",
       "24127     1502.0     60      57    359.0 2004-06-14 21:09:23   \n",
       "\n",
       "                                           movie_sequence  \\\n",
       "109333  [6825.0, 6825.0, 6825.0, 6825.0, 6825.0, 6825....   \n",
       "65022   [72224.0, 72224.0, 72224.0, 72224.0, 72224.0, ...   \n",
       "56562   [32460.0, 32460.0, 32460.0, 32460.0, 32460.0, ...   \n",
       "119782  [113501.0, 113501.0, 113501.0, 113501.0, 11350...   \n",
       "24127   [3192.0, 3192.0, 3192.0, 3192.0, 3192.0, 3192....   \n",
       "\n",
       "                                           genre_sequence  \\\n",
       "109333  [31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3...   \n",
       "65022   [31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3...   \n",
       "56562   [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "119782  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "24127   [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...   \n",
       "\n",
       "                                        datetime_sequence  \\\n",
       "109333  [2004-01-17 01:59:42, 2004-01-17 01:59:42, 200...   \n",
       "65022   [2010-03-22 02:41:56, 2010-03-22 02:41:56, 201...   \n",
       "56562   [2008-06-19 20:16:53, 2008-06-19 20:16:53, 200...   \n",
       "119782  [2014-12-02 04:28:57, 2014-12-02 04:28:57, 201...   \n",
       "24127   [2003-10-26 16:08:07, 2003-10-26 16:08:07, 200...   \n",
       "\n",
       "                                           title_sequence  \n",
       "109333  [94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 9...  \n",
       "65022   [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...  \n",
       "56562   [61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 6...  \n",
       "119782  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "24127   [117, 117, 117, 117, 117, 117, 117, 117, 117, ...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftraining.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115092, 9)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftraining.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId              0\n",
       "title                0\n",
       "genres               0\n",
       "userId               0\n",
       "datetime             0\n",
       "movie_sequence       0\n",
       "genre_sequence       0\n",
       "datetime_sequence    0\n",
       "title_sequence       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftraining.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId              0\n",
       "title                0\n",
       "genres               0\n",
       "userId               0\n",
       "datetime             0\n",
       "movie_sequence       0\n",
       "genre_sequence       0\n",
       "datetime_sequence    0\n",
       "title_sequence       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftesting.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdftraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "dftraining.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dftraining['datetime'] = pd.to_datetime(dftraining['datetime'])\n",
    "\n",
    "\n",
    "dftraining = dftraining.drop(columns=['rating', 'tagId', 'relevance'])\n",
    "\n",
    "# Sort the dataset by 'userId' and 'datetime' to ensure correct temporal order\n",
    "dftraining = dftraining.sort_values(by=['userId', 'datetime'])\n",
    "\n",
    "# Group by 'userId' and create sequences of 'movieId' and 'genres'\n",
    "user_sequences_with_details = dftraining.groupby('userId').agg(\n",
    "    movie_sequence=('movieId', lambda x: list(x)),\n",
    "    genre_sequence=('genres', lambda x: list(x)),\n",
    "    datetime=('datetime', lambda x: list(x)),  \n",
    "    title=('title', lambda x: list(x))         \n",
    ").reset_index()\n",
    "\n",
    "# Merge the sequence details with the original DataFrame\n",
    "dffinal = pd.merge(dftraining, user_sequences_with_details[['userId', 'movie_sequence', 'genre_sequence']], on='userId', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>userId</th>\n",
       "      <th>datetime</th>\n",
       "      <th>movie_sequence</th>\n",
       "      <th>genre_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27866.0</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2011-05-09 16:05:59</td>\n",
       "      <td>[27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27866.0</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2011-05-09 16:05:59</td>\n",
       "      <td>[27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27866.0</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2011-05-09 16:05:59</td>\n",
       "      <td>[27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27866.0</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2011-05-09 16:05:59</td>\n",
       "      <td>[27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27866.0</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2011-05-09 16:05:59</td>\n",
       "      <td>[27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...</td>\n",
       "      <td>[52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  title  genres  userId            datetime  \\\n",
       "0  27866.0     55      52    65.0 2011-05-09 16:05:59   \n",
       "1  27866.0     55      52    65.0 2011-05-09 16:05:59   \n",
       "2  27866.0     55      52    65.0 2011-05-09 16:05:59   \n",
       "3  27866.0     55      52    65.0 2011-05-09 16:05:59   \n",
       "4  27866.0     55      52    65.0 2011-05-09 16:05:59   \n",
       "\n",
       "                                      movie_sequence  \\\n",
       "0  [27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...   \n",
       "1  [27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...   \n",
       "2  [27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...   \n",
       "3  [27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...   \n",
       "4  [27866.0, 27866.0, 27866.0, 27866.0, 27866.0, ...   \n",
       "\n",
       "                                      genre_sequence  \n",
       "0  [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...  \n",
       "1  [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...  \n",
       "2  [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...  \n",
       "3  [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...  \n",
       "4  [52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 5...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115092, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdffinal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduplicated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6958\u001b[0m, in \u001b[0;36mDataFrame.duplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6957\u001b[0m     vals \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m subset)\n\u001b[1;32m-> 6958\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   6960\u001b[0m     ids \u001b[38;5;241m=\u001b[39m get_group_index(labels, \u001b[38;5;28mtuple\u001b[39m(shape), sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, xnull\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6961\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_sliced(duplicated(ids, keep), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:6926\u001b[0m, in \u001b[0;36mDataFrame.duplicated.<locals>.f\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   6925\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(vals) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m-> 6926\u001b[0m     labels, shape \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28mlen\u001b[39m(shape)\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[0m, in \u001b[0;36mfactorize\u001b[1;34m(values, sort, use_na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[0;32m    793\u001b[0m             values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(null_mask, na_value, values)\n\u001b[1;32m--> 795\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    802\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m safe_sort(\n\u001b[0;32m    803\u001b[0m         uniques,\n\u001b[0;32m    804\u001b[0m         codes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    807\u001b[0m         verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    808\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\SOOQ ELASER\\movie_recomendation_collaborative_filtering\\venv\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[0m, in \u001b[0;36mfactorize_array\u001b[1;34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    592\u001b[0m hash_klass, values \u001b[38;5;241m=\u001b[39m _get_hashtable_algo(values)\n\u001b[0;32m    594\u001b[0m table \u001b[38;5;241m=\u001b[39m hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m--> 595\u001b[0m uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[0;32m    604\u001b[0m uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7281\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "dffinal.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId                  float64\n",
       "title                      int64\n",
       "genres                     int64\n",
       "userId                   float64\n",
       "datetime          datetime64[ns]\n",
       "movie_sequence            object\n",
       "genre_sequence            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffinal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
